{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26aecda-f510-4d45-8f29-7567f94bd8b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Given our target variable ('total_cost') is a continuous variable, this is a regression problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690ecda3-b423-4b2e-92e9-492a58d357bd",
   "metadata": {},
   "source": [
    "Here's a simplified step-by-step guide using Python and scikit-learn, a popular machine learning library:\n",
    "\n",
    "1. Data Preprocessing:\n",
    "    - Handle missing values: Check and handle missing values in your dataset.\n",
    "    - Encode categorical variables: Convert categorical variables into numerical format, as most machine learning models require numerical input.\n",
    "    \n",
    "2. Feature Selection:\n",
    "    - Identify relevant features: Select features that are likely to have an impact on predicting 'total_cost.'\n",
    "    \n",
    "3. Split the Data:\n",
    "    - Split your dataset into a training set and a testing set. The training set is used to train the model, and the testing set is used to evaluate its performance.\n",
    "\n",
    "4. Build a Model:\n",
    "    - Choose a regression algorithm: Common choices include Linear Regression, Decision Trees, Random Forest, Gradient Boosting, or Support Vector Machines.\n",
    "    - Train the model using the training data.\n",
    "\n",
    "5. Evaluate the Model:\n",
    "    - Use the testing set to evaluate the model's performance.\n",
    "    - Common evaluation metrics for regression include Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared.\n",
    "\n",
    "6. Tune and Improve:\n",
    "    - If the model performance is not satisfactory, you may need to fine-tune hyperparameters or try different algorithms.\n",
    "    - Feature engineering: Experiment with creating new features or transforming existing ones to improve model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1634e0bc-fceb-4417-992b-22b008efdfa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2b2b0c41-27f0-442e-91e4-a913d708a08f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 6109365.916803202\n",
      "Mean Squared Error: 108286955223790.94\n",
      "R-squared: 0.23309402707635152\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('savegame.csv')\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['tour_arrangement'] = label_encoder.fit_transform(df['tour_arrangement'])\n",
    "df['main_activity'] = label_encoder.fit_transform(df['main_activity'])\n",
    "\n",
    "# Select features and target\n",
    "features = df[['tour_arrangement', 'main_activity', 'night_total']]\n",
    "target = df['total_cost']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('R-squared:', r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b60c6c-5717-412a-a244-3371d27da25d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f338c7-b24f-4b8d-8dad-43aa1ba1c3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78026e-ac4e-4214-b3f6-7700f314bf16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9b608e45-b1ea-4857-92ba-490994ed89bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 6159056.626087277\n",
      "Mean Squared Error: 102174374823900.92\n",
      "R-squared: 0.2763843237604138\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('savegame.csv')\n",
    "\n",
    "# Split the data\n",
    "features = df[['tour_arrangement', 'main_activity', 'night_total', 'country', 'age_group']]\n",
    "target = df['total_cost']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the numerical and categorical features\n",
    "numeric_features = ['night_total']\n",
    "categorical_features = ['tour_arrangement', 'main_activity', 'country', 'age_group']\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "\n",
    "    \n",
    "])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessor and the regression model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', LinearRegression())])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('R-squared:', r2_score(y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e04c3e3-b2a9-4171-9763-e945d7b56717",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o=OneHotEncoder()\n",
    "o.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b4be836f-3d9f-483b-8b29-ff890ff350f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END .......................regressor=LinearRegression(); total time=   0.0s\n",
      "[CV] END .......................regressor=LinearRegression(); total time=   0.0s\n",
      "[CV] END .......................regressor=LinearRegression(); total time=   0.0s\n",
      "[CV] END .......................regressor=LinearRegression(); total time=   0.0s\n",
      "[CV] END .......................regressor=LinearRegression(); total time=   0.0s\n",
      "[CV] END .........................regressor=Ridge(alpha=0.5); total time=   0.0s\n",
      "[CV] END .........................regressor=Ridge(alpha=0.5); total time=   0.0s\n",
      "[CV] END .........................regressor=Ridge(alpha=0.5); total time=   0.0s\n",
      "[CV] END .........................regressor=Ridge(alpha=0.5); total time=   0.0s\n",
      "[CV] END .........................regressor=Ridge(alpha=0.5); total time=   0.0s\n",
      "[CV] END ..................regressor=DecisionTreeRegressor(); total time=   0.0s\n",
      "[CV] END ..................regressor=DecisionTreeRegressor(); total time=   0.0s\n",
      "[CV] END ..................regressor=DecisionTreeRegressor(); total time=   0.0s\n",
      "[CV] END ..................regressor=DecisionTreeRegressor(); total time=   0.0s\n",
      "[CV] END ..................regressor=DecisionTreeRegressor(); total time=   0.0s\n",
      "[CV] END ..................regressor=RandomForestRegressor(); total time=   1.1s\n",
      "[CV] END ..................regressor=RandomForestRegressor(); total time=   1.1s\n",
      "[CV] END ..................regressor=RandomForestRegressor(); total time=   1.1s\n",
      "[CV] END ..................regressor=RandomForestRegressor(); total time=   1.1s\n",
      "[CV] END ..................regressor=RandomForestRegressor(); total time=   1.1s\n",
      "[CV] END regressor=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...); total time=   0.2s\n",
      "[CV] END regressor=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...); total time=   0.2s\n",
      "[CV] END regressor=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...); total time=   0.1s\n",
      "[CV] END regressor=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...); total time=   0.1s\n",
      "[CV] END regressor=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=None, ...); total time=   0.2s\n",
      "Best Model: Ridge(alpha=0.5)\n",
      "Mean Absolute Error: 6129695.204766839\n",
      "Mean Squared Error: 101140285534400.6\n",
      "R-squared: 0.2837079136703454\n",
      "MAPE: 533.92%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {color: black;background-color: white;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;night_total&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;tour_arrangement&#x27;,\n",
       "                                                   &#x27;main_activity&#x27;, &#x27;country&#x27;,\n",
       "                                                   &#x27;age_group&#x27;,\n",
       "                                                   &#x27;most_impressing&#x27;,\n",
       "                                                   &#x27;first_trip_tz&#x27;,\n",
       "                                                   &#x27;info_source&#x27;])])),\n",
       "                (&#x27;regressor&#x27;, Ridge(alpha=0.5))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-238\" type=\"checkbox\" ><label for=\"sk-estimator-id-238\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;night_total&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;tour_arrangement&#x27;,\n",
       "                                                   &#x27;main_activity&#x27;, &#x27;country&#x27;,\n",
       "                                                   &#x27;age_group&#x27;,\n",
       "                                                   &#x27;most_impressing&#x27;,\n",
       "                                                   &#x27;first_trip_tz&#x27;,\n",
       "                                                   &#x27;info_source&#x27;])])),\n",
       "                (&#x27;regressor&#x27;, Ridge(alpha=0.5))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-239\" type=\"checkbox\" ><label for=\"sk-estimator-id-239\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;night_total&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;tour_arrangement&#x27;, &#x27;main_activity&#x27;,\n",
       "                                  &#x27;country&#x27;, &#x27;age_group&#x27;, &#x27;most_impressing&#x27;,\n",
       "                                  &#x27;first_trip_tz&#x27;, &#x27;info_source&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-240\" type=\"checkbox\" ><label for=\"sk-estimator-id-240\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;night_total&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-241\" type=\"checkbox\" ><label for=\"sk-estimator-id-241\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-242\" type=\"checkbox\" ><label for=\"sk-estimator-id-242\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-243\" type=\"checkbox\" ><label for=\"sk-estimator-id-243\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;tour_arrangement&#x27;, &#x27;main_activity&#x27;, &#x27;country&#x27;, &#x27;age_group&#x27;, &#x27;most_impressing&#x27;, &#x27;first_trip_tz&#x27;, &#x27;info_source&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-244\" type=\"checkbox\" ><label for=\"sk-estimator-id-244\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-245\" type=\"checkbox\" ><label for=\"sk-estimator-id-245\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-246\" type=\"checkbox\" ><label for=\"sk-estimator-id-246\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=0.5)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['night_total']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['tour_arrangement',\n",
       "                                                   'main_activity', 'country',\n",
       "                                                   'age_group',\n",
       "                                                   'most_impressing',\n",
       "                                                   'first_trip_tz',\n",
       "                                                   'info_source'])])),\n",
       "                ('regressor', Ridge(alpha=0.5))])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load your data (replace 'your_data.csv' with the actual file name)\n",
    "df = pd.read_csv('savegame.csv')\n",
    "\n",
    "# Split the data\n",
    "features = df[['tour_arrangement', 'main_activity', 'night_total', 'country', 'age_group', 'most_impressing', 'first_trip_tz', 'info_source']]\n",
    "target = df['total_cost']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the numerical and categorical features\n",
    "numeric_features = ['night_total']\n",
    "categorical_features = ['tour_arrangement', 'main_activity', 'country', 'age_group', 'most_impressing', 'first_trip_tz', 'info_source']\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessor and a regression model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('regressor', LinearRegression())])\n",
    "\n",
    "# Define a parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'regressor': [LinearRegression(), Ridge(alpha=0.5), DecisionTreeRegressor(), RandomForestRegressor(), XGBRegressor()],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "print('Best Model:', best_model.named_steps['regressor'])\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('R-squared:', r2_score(y_test, predictions))\n",
    "\n",
    "def calculate_mape(actual, predicted):\n",
    "    return np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "mape_value = calculate_mape(y_test, predictions)\n",
    "print(f'MAPE: {mape_value:.2f}%')\n",
    "\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35414b93-5d18-43f9-8a40-6c5c64713098",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "32c0c5d4-cd32-4269-8699-5cb72095016f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 5507358.952724207\n",
      "Mean Squared Error: 100199676884897.12\n",
      "R-squared: 0.2903694583596117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load your data (replace 'your_data.csv' with the actual file name)\n",
    "df = pd.read_csv('savegame.csv')\n",
    "\n",
    "# Split the data\n",
    "features = df[['tour_arrangement', 'main_activity', 'purpose', 'night_total', 'age_group', 'travel_with']]\n",
    "target = df['total_cost']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the numerical and categorical features\n",
    "numeric_features     = ['night_total']\n",
    "categorical_features = ['tour_arrangement', 'main_activity', 'purpose', 'night_total', 'age_group', 'travel_with']\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessor and XGBoost regressor\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                            ('regressor', XGBRegressor())])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('R-squared:', r2_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd471a5-0339-4138-91e2-7868d2b35666",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8669f198-4a2e-4063-9b04-91e6426332de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.model_serializer import ModelSerializer\n",
    "\n",
    "serializer = ModelSerializer('models/blabla.bla')\n",
    "serializer.dump(pipeline)\n",
    "\n",
    "# Loading the Model\n",
    "# serializer = ModelSerializer('models/blabla.bla')\n",
    "#pipeline = serializer.load()\n",
    "#pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c537e46-1be8-4b89-bb56-b987a59fbda8",
   "metadata": {},
   "source": [
    "In this example:\n",
    "\n",
    "The ColumnTransformer is used to apply different transformations to numerical and categorical features separately.\n",
    "The Pipeline includes both preprocessing steps and the regression model.\n",
    "Numerical features are imputed with the mean and scaled using StandardScaler.\n",
    "Categorical features are imputed with the most frequent value and one-hot encoded using OneHotEncoder.\n",
    "This pipeline allows for a cleaner and more organized approach to data preprocessing and model building. Adjust the column names and other parameters based on your specific dataset and requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b238a40f-1b19-4b8d-b427-c7a74df3139a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Mean Absolute Error: 5520792.649007987\n",
      "Mean Squared Error: 109639976056711.22\n",
      "R-squared: 0.22351171168007633\n",
      "\n",
      "XGBoost Metrics:\n",
      "Mean Absolute Error: 5681060.104981062\n",
      "Mean Squared Error: 115560834311945.83\n",
      "R-squared: 0.18157922266152737\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load your data (replace 'your_data.csv' with the actual file name)\n",
    "df = pd.read_csv('savegame.csv')\n",
    "\n",
    "# Define features (add more columns as needed)\n",
    "features = df[['tour_arrangement', 'main_activity', 'night_total', 'age_group', 'travel_with', 'total_female', 'total_male']]\n",
    "\n",
    "# Add more numerical and categorical features based on your data\n",
    "numeric_features = ['night_total', 'total_female', 'total_male']\n",
    "categorical_features = ['tour_arrangement', 'main_activity', 'age_group', 'travel_with']\n",
    "\n",
    "# Split the data\n",
    "target = df['total_cost']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessor and Random Forest Regressor\n",
    "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('regressor', RandomForestRegressor())])\n",
    "\n",
    "# Create a pipeline with the preprocessor and XGBoost Regressor\n",
    "xgb_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('regressor', XGBRegressor())])\n",
    "\n",
    "# Fit and evaluate Random Forest\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "rf_predictions = rf_pipeline.predict(X_test)\n",
    "\n",
    "# Fit and evaluate XGBoost\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "print(\"Random Forest Metrics:\")\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, rf_predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, rf_predictions))\n",
    "print('R-squared:', r2_score(y_test, rf_predictions))\n",
    "\n",
    "print(\"\\nXGBoost Metrics:\")\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, xgb_predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, xgb_predictions))\n",
    "print('R-squared:', r2_score(y_test, xgb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7002265-092a-4fc4-ae8f-16c5f561cdc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Results:\n",
      "Mean Absolute Error: 5677866.177860651\n",
      "Mean Squared Error: 133249143149661.16\n",
      "R-squared: 0.10820736470381032\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean Squared Error:\u001b[39m\u001b[38;5;124m'\u001b[39m, mean_squared_error(target, predictions_inverse))\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR-squared:\u001b[39m\u001b[38;5;124m'\u001b[39m, r2_score(target, predictions_inverse))\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_inverse\u001b[49m\u001b[43m)\u001b[49m    )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/pipeline.py:718\u001b[0m, in \u001b[0;36mPipeline.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    716\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 718\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m score_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:770\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    754\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform X separately by each transformer, concatenate results.\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \n\u001b[1;32m    756\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;124;03m        sparse matrices.\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 770\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    771\u001b[0m     X \u001b[38;5;241m=\u001b[39m _check_X(X)\n\u001b[1;32m    773\u001b[0m     fit_dataframe_and_transform_dataframe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    775\u001b[0m     ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/utils/validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1386\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1387\u001b[0m     ]\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[0;32m-> 1390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load your data (replace 'your_data.csv' with the actual file name)\n",
    "df = pd.read_csv('savegame.csv')\n",
    "\n",
    "# Split the data\n",
    "features = df[['tour_arrangement', 'main_activity', 'night_total', 'age_group', 'purpose']]\n",
    "target = df['total_cost']\n",
    "\n",
    "# Log-transform the target variable\n",
    "target_log = np.log1p(target)\n",
    "\n",
    "# Define the numerical and categorical features\n",
    "numeric_features = ['night_total']\n",
    "categorical_features = ['tour_arrangement', 'main_activity']\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessor and XGBoost regressor\n",
    "xgboost_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                    ('regressor', XGBRegressor())])\n",
    "\n",
    "# Create a pipeline with the preprocessor and Linear Regression\n",
    "linear_regression_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                              ('regressor', LinearRegression())])\n",
    "\n",
    "# Create a pipeline with the preprocessor and RandomForestRegressor\n",
    "random_forest_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                          ('regressor', RandomForestRegressor())])\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'XGBoost': xgboost_pipeline,\n",
    "    'Linear Regression': linear_regression_pipeline,\n",
    "    'Random Forest': random_forest_pipeline\n",
    "}\n",
    "\n",
    "# Evaluate each model using k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f'\\n{model_name} Results:')\n",
    "\n",
    "    # Use cross_val_predict for k-fold cross-validation\n",
    "    predictions_log = cross_val_predict(model, features, target_log, cv=kf)\n",
    "    \n",
    "    # Inverse transform log predictions\n",
    "    predictions_inverse = np.expm1(predictions_log)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print('Mean Absolute Error:', mean_absolute_error(target, predictions_inverse))\n",
    "    print('Mean Squared Error:', mean_squared_error(target, predictions_inverse))\n",
    "    print('R-squared:', r2_score(target, predictions_inverse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
